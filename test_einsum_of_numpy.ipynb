{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#einsum 是numpy的一个函数，实现了爱因斯坦求和约定，可以实现多维数组的许多基本运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#向量内积(又叫数量积, 点乘)\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "c = np.einsum(\"i,i->\",a,b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.,  6., -3.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#向量矢积(又叫向量积, 叉乘)\n",
    "\n",
    "e = np.zeros((3, 3, 3))\n",
    "e[0, 1, 2] = e[1, 2, 0] = e[2, 0, 1] = 1\n",
    "e[0, 2, 1] = e[2, 1, 0] = e[1, 0, 2] = -1\n",
    "\n",
    "\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "c = np.einsum(\"i,j,ijk->k\",a,b,e)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  5,  6],\n",
       "       [ 8, 10, 12],\n",
       "       [12, 15, 18]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#向量外积(又叫张量积, 并失)\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "c = np.einsum(\"i,j->ij\",a,b)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#矩阵求迹\n",
    "a = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "c = np.einsum(\"ii->\",a)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#矩阵求所有元素和\n",
    "a = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "c = np.einsum(\"ij->\",a)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 15, 18])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#矩阵沿i方向(第0轴)求和\n",
    "a = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "c = np.einsum(\"ij->j\",a)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 15, 24])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#矩阵沿j方向(第1轴)求和\n",
    "a = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "c = np.einsum(\"ij->i\",a)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 7],\n",
       "       [2, 5, 8],\n",
       "       [3, 6, 9]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#矩阵转置\n",
    "a = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "c = np.einsum(\"ij->ji\",a)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30,  24,  18],\n",
       "       [ 84,  69,  54],\n",
       "       [138, 114,  90]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#矩阵相乘\n",
    "a = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "b = np.array([[9,8,7],[6,5,4],[3,2,1]])\n",
    "c = np.einsum(\"ik,kj->ij\",a,b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 9,  8,  7],\n",
       "         [ 6,  5,  4],\n",
       "         [ 3,  2,  1]],\n",
       "\n",
       "        [[18, 16, 14],\n",
       "         [12, 10,  8],\n",
       "         [ 6,  4,  2]],\n",
       "\n",
       "        [[27, 24, 21],\n",
       "         [18, 15, 12],\n",
       "         [ 9,  6,  3]]],\n",
       "\n",
       "\n",
       "       [[[36, 32, 28],\n",
       "         [24, 20, 16],\n",
       "         [12,  8,  4]],\n",
       "\n",
       "        [[45, 40, 35],\n",
       "         [30, 25, 20],\n",
       "         [15, 10,  5]],\n",
       "\n",
       "        [[54, 48, 42],\n",
       "         [36, 30, 24],\n",
       "         [18, 12,  6]]],\n",
       "\n",
       "\n",
       "       [[[63, 56, 49],\n",
       "         [42, 35, 28],\n",
       "         [21, 14,  7]],\n",
       "\n",
       "        [[72, 64, 56],\n",
       "         [48, 40, 32],\n",
       "         [24, 16,  8]],\n",
       "\n",
       "        [[81, 72, 63],\n",
       "         [54, 45, 36],\n",
       "         [27, 18,  9]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#用矩阵表示的(二阶张量)张量积\n",
    "a = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "b = np.array([[9,8,7],[6,5,4],[3,2,1]])\n",
    "c = np.einsum(\"ij,kl->ijkl\",a,b)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 45, 126, 207])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#用三维数组表示的(三阶张量)缩并 后两个指标\n",
    "a = np.array([[[ 1,  2,  3],\n",
    "         [ 4,  5,  6],\n",
    "         [ 7,  8,  9]],\n",
    "\n",
    "        [[10, 11, 12],\n",
    "         [13, 14,  15],\n",
    "         [ 16,  17,  18]],\n",
    "\n",
    "        [[19, 20, 21],\n",
    "         [22, 23, 24],\n",
    "         [ 25,  26,  27]]])\n",
    "\n",
    "c = np.einsum(\"ijk->i\",a)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 函数文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function einsum in module numpy:\n",
      "\n",
      "einsum(*operands, **kwargs)\n",
      "    einsum(subscripts, *operands, out=None, dtype=None, order='K',\n",
      "           casting='safe', optimize=False)\n",
      "    \n",
      "    Evaluates the Einstein summation convention on the operands.\n",
      "    \n",
      "    Using the Einstein summation convention, many common multi-dimensional,\n",
      "    linear algebraic array operations can be represented in a simple fashion.\n",
      "    In *implicit* mode `einsum` computes these values.\n",
      "    \n",
      "    In *explicit* mode, `einsum` provides further flexibility to compute\n",
      "    other array operations that might not be considered classical Einstein\n",
      "    summation operations, by disabling, or forcing summation over specified\n",
      "    subscript labels.\n",
      "    \n",
      "    See the notes and examples for clarification.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    subscripts : str\n",
      "        Specifies the subscripts for summation as comma separated list of\n",
      "        subscript labels. An implicit (classical Einstein summation)\n",
      "        calculation is performed unless the explicit indicator '->' is\n",
      "        included as well as subscript labels of the precise output form.\n",
      "    operands : list of array_like\n",
      "        These are the arrays for the operation.\n",
      "    out : ndarray, optional\n",
      "        If provided, the calculation is done into this array.\n",
      "    dtype : {data-type, None}, optional\n",
      "        If provided, forces the calculation to use the data type specified.\n",
      "        Note that you may have to also give a more liberal `casting`\n",
      "        parameter to allow the conversions. Default is None.\n",
      "    order : {'C', 'F', 'A', 'K'}, optional\n",
      "        Controls the memory layout of the output. 'C' means it should\n",
      "        be C contiguous. 'F' means it should be Fortran contiguous,\n",
      "        'A' means it should be 'F' if the inputs are all 'F', 'C' otherwise.\n",
      "        'K' means it should be as close to the layout as the inputs as\n",
      "        is possible, including arbitrarily permuted axes.\n",
      "        Default is 'K'.\n",
      "    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "        Controls what kind of data casting may occur.  Setting this to\n",
      "        'unsafe' is not recommended, as it can adversely affect accumulations.\n",
      "    \n",
      "          * 'no' means the data types should not be cast at all.\n",
      "          * 'equiv' means only byte-order changes are allowed.\n",
      "          * 'safe' means only casts which can preserve values are allowed.\n",
      "          * 'same_kind' means only safe casts or casts within a kind,\n",
      "            like float64 to float32, are allowed.\n",
      "          * 'unsafe' means any data conversions may be done.\n",
      "    \n",
      "        Default is 'safe'.\n",
      "    optimize : {False, True, 'greedy', 'optimal'}, optional\n",
      "        Controls if intermediate optimization should occur. No optimization\n",
      "        will occur if False and True will default to the 'greedy' algorithm.\n",
      "        Also accepts an explicit contraction list from the ``np.einsum_path``\n",
      "        function. See ``np.einsum_path`` for more details. Defaults to False.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    output : ndarray\n",
      "        The calculation based on the Einstein summation convention.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    einsum_path, dot, inner, outer, tensordot, linalg.multi_dot\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 1.6.0\n",
      "    \n",
      "    The Einstein summation convention can be used to compute\n",
      "    many multi-dimensional, linear algebraic array operations. `einsum`\n",
      "    provides a succinct way of representing these.\n",
      "    \n",
      "    A non-exhaustive list of these operations,\n",
      "    which can be computed by `einsum`, is shown below along with examples:\n",
      "    \n",
      "    * Trace of an array, :py:func:`numpy.trace`.\n",
      "    * Return a diagonal, :py:func:`numpy.diag`.\n",
      "    * Array axis summations, :py:func:`numpy.sum`.\n",
      "    * Transpositions and permutations, :py:func:`numpy.transpose`.\n",
      "    * Matrix multiplication and dot product, :py:func:`numpy.matmul` :py:func:`numpy.dot`.\n",
      "    * Vector inner and outer products, :py:func:`numpy.inner` :py:func:`numpy.outer`.\n",
      "    * Broadcasting, element-wise and scalar multiplication, :py:func:`numpy.multiply`.\n",
      "    * Tensor contractions, :py:func:`numpy.tensordot`.\n",
      "    * Chained array operations, in efficient calculation order, :py:func:`numpy.einsum_path`.\n",
      "    \n",
      "    The subscripts string is a comma-separated list of subscript labels,\n",
      "    where each label refers to a dimension of the corresponding operand.\n",
      "    Whenever a label is repeated it is summed, so ``np.einsum('i,i', a, b)``\n",
      "    is equivalent to :py:func:`np.inner(a,b) <numpy.inner>`. If a label\n",
      "    appears only once, it is not summed, so ``np.einsum('i', a)`` produces a\n",
      "    view of ``a`` with no changes. A further example ``np.einsum('ij,jk', a, b)``\n",
      "    describes traditional matrix multiplication and is equivalent to\n",
      "    :py:func:`np.matmul(a,b) <numpy.matmul>`. Repeated subscript labels in one\n",
      "    operand take the diagonal. For example, ``np.einsum('ii', a)`` is equivalent\n",
      "    to :py:func:`np.trace(a) <numpy.trace>`.\n",
      "    \n",
      "    In *implicit mode*, the chosen subscripts are important\n",
      "    since the axes of the output are reordered alphabetically.  This\n",
      "    means that ``np.einsum('ij', a)`` doesn't affect a 2D array, while\n",
      "    ``np.einsum('ji', a)`` takes its transpose. Additionally,\n",
      "    ``np.einsum('ij,jk', a, b)`` returns a matrix multiplication, while,\n",
      "    ``np.einsum('ij,jh', a, b)`` returns the transpose of the\n",
      "    multiplication since subscript 'h' precedes subscript 'i'.\n",
      "    \n",
      "    In *explicit mode* the output can be directly controlled by\n",
      "    specifying output subscript labels.  This requires the\n",
      "    identifier '->' as well as the list of output subscript labels.\n",
      "    This feature increases the flexibility of the function since\n",
      "    summing can be disabled or forced when required. The call\n",
      "    ``np.einsum('i->', a)`` is like :py:func:`np.sum(a, axis=-1) <numpy.sum>`,\n",
      "    and ``np.einsum('ii->i', a)`` is like :py:func:`np.diag(a) <numpy.diag>`.\n",
      "    The difference is that `einsum` does not allow broadcasting by default.\n",
      "    Additionally ``np.einsum('ij,jh->ih', a, b)`` directly specifies the\n",
      "    order of the output subscript labels and therefore returns matrix\n",
      "    multiplication, unlike the example above in implicit mode.\n",
      "    \n",
      "    To enable and control broadcasting, use an ellipsis.  Default\n",
      "    NumPy-style broadcasting is done by adding an ellipsis\n",
      "    to the left of each term, like ``np.einsum('...ii->...i', a)``.\n",
      "    To take the trace along the first and last axes,\n",
      "    you can do ``np.einsum('i...i', a)``, or to do a matrix-matrix\n",
      "    product with the left-most indices instead of rightmost, one can do\n",
      "    ``np.einsum('ij...,jk...->ik...', a, b)``.\n",
      "    \n",
      "    When there is only one operand, no axes are summed, and no output\n",
      "    parameter is provided, a view into the operand is returned instead\n",
      "    of a new array.  Thus, taking the diagonal as ``np.einsum('ii->i', a)``\n",
      "    produces a view (changed in version 1.10.0).\n",
      "    \n",
      "    `einsum` also provides an alternative way to provide the subscripts\n",
      "    and operands as ``einsum(op0, sublist0, op1, sublist1, ..., [sublistout])``.\n",
      "    If the output shape is not provided in this format `einsum` will be\n",
      "    calculated in implicit mode, otherwise it will be performed explicitly.\n",
      "    The examples below have corresponding `einsum` calls with the two\n",
      "    parameter methods.\n",
      "    \n",
      "    .. versionadded:: 1.10.0\n",
      "    \n",
      "    Views returned from einsum are now writeable whenever the input array\n",
      "    is writeable. For example, ``np.einsum('ijk...->kji...', a)`` will now\n",
      "    have the same effect as :py:func:`np.swapaxes(a, 0, 2) <numpy.swapaxes>`\n",
      "    and ``np.einsum('ii->i', a)`` will return a writeable view of the diagonal\n",
      "    of a 2D array.\n",
      "    \n",
      "    .. versionadded:: 1.12.0\n",
      "    \n",
      "    Added the ``optimize`` argument which will optimize the contraction order\n",
      "    of an einsum expression. For a contraction with three or more operands this\n",
      "    can greatly increase the computational efficiency at the cost of a larger\n",
      "    memory footprint during computation.\n",
      "    \n",
      "    Typically a 'greedy' algorithm is applied which empirical tests have shown\n",
      "    returns the optimal path in the majority of cases. In some cases 'optimal'\n",
      "    will return the superlative path through a more expensive, exhaustive search.\n",
      "    For iterative calculations it may be advisable to calculate the optimal path\n",
      "    once and reuse that path by supplying it as an argument. An example is given\n",
      "    below.\n",
      "    \n",
      "    See :py:func:`numpy.einsum_path` for more details.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(25).reshape(5,5)\n",
      "    >>> b = np.arange(5)\n",
      "    >>> c = np.arange(6).reshape(2,3)\n",
      "    \n",
      "    Trace of a matrix:\n",
      "    \n",
      "    >>> np.einsum('ii', a)\n",
      "    60\n",
      "    >>> np.einsum(a, [0,0])\n",
      "    60\n",
      "    >>> np.trace(a)\n",
      "    60\n",
      "    \n",
      "    Extract the diagonal (requires explicit form):\n",
      "    \n",
      "    >>> np.einsum('ii->i', a)\n",
      "    array([ 0,  6, 12, 18, 24])\n",
      "    >>> np.einsum(a, [0,0], [0])\n",
      "    array([ 0,  6, 12, 18, 24])\n",
      "    >>> np.diag(a)\n",
      "    array([ 0,  6, 12, 18, 24])\n",
      "    \n",
      "    Sum over an axis (requires explicit form):\n",
      "    \n",
      "    >>> np.einsum('ij->i', a)\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "    >>> np.einsum(a, [0,1], [0])\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "    >>> np.sum(a, axis=1)\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "    \n",
      "    For higher dimensional arrays summing a single axis can be done with ellipsis:\n",
      "    \n",
      "    >>> np.einsum('...j->...', a)\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "    >>> np.einsum(a, [Ellipsis,1], [Ellipsis])\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "    \n",
      "    Compute a matrix transpose, or reorder any number of axes:\n",
      "    \n",
      "    >>> np.einsum('ji', c)\n",
      "    array([[0, 3],\n",
      "           [1, 4],\n",
      "           [2, 5]])\n",
      "    >>> np.einsum('ij->ji', c)\n",
      "    array([[0, 3],\n",
      "           [1, 4],\n",
      "           [2, 5]])\n",
      "    >>> np.einsum(c, [1,0])\n",
      "    array([[0, 3],\n",
      "           [1, 4],\n",
      "           [2, 5]])\n",
      "    >>> np.transpose(c)\n",
      "    array([[0, 3],\n",
      "           [1, 4],\n",
      "           [2, 5]])\n",
      "    \n",
      "    Vector inner products:\n",
      "    \n",
      "    >>> np.einsum('i,i', b, b)\n",
      "    30\n",
      "    >>> np.einsum(b, [0], b, [0])\n",
      "    30\n",
      "    >>> np.inner(b,b)\n",
      "    30\n",
      "    \n",
      "    Matrix vector multiplication:\n",
      "    \n",
      "    >>> np.einsum('ij,j', a, b)\n",
      "    array([ 30,  80, 130, 180, 230])\n",
      "    >>> np.einsum(a, [0,1], b, [1])\n",
      "    array([ 30,  80, 130, 180, 230])\n",
      "    >>> np.dot(a, b)\n",
      "    array([ 30,  80, 130, 180, 230])\n",
      "    >>> np.einsum('...j,j', a, b)\n",
      "    array([ 30,  80, 130, 180, 230])\n",
      "    \n",
      "    Broadcasting and scalar multiplication:\n",
      "    \n",
      "    >>> np.einsum('..., ...', 3, c)\n",
      "    array([[ 0,  3,  6],\n",
      "           [ 9, 12, 15]])\n",
      "    >>> np.einsum(',ij', 3, c)\n",
      "    array([[ 0,  3,  6],\n",
      "           [ 9, 12, 15]])\n",
      "    >>> np.einsum(3, [Ellipsis], c, [Ellipsis])\n",
      "    array([[ 0,  3,  6],\n",
      "           [ 9, 12, 15]])\n",
      "    >>> np.multiply(3, c)\n",
      "    array([[ 0,  3,  6],\n",
      "           [ 9, 12, 15]])\n",
      "    \n",
      "    Vector outer product:\n",
      "    \n",
      "    >>> np.einsum('i,j', np.arange(2)+1, b)\n",
      "    array([[0, 1, 2, 3, 4],\n",
      "           [0, 2, 4, 6, 8]])\n",
      "    >>> np.einsum(np.arange(2)+1, [0], b, [1])\n",
      "    array([[0, 1, 2, 3, 4],\n",
      "           [0, 2, 4, 6, 8]])\n",
      "    >>> np.outer(np.arange(2)+1, b)\n",
      "    array([[0, 1, 2, 3, 4],\n",
      "           [0, 2, 4, 6, 8]])\n",
      "    \n",
      "    Tensor contraction:\n",
      "    \n",
      "    >>> a = np.arange(60.).reshape(3,4,5)\n",
      "    >>> b = np.arange(24.).reshape(4,3,2)\n",
      "    >>> np.einsum('ijk,jil->kl', a, b)\n",
      "    array([[ 4400.,  4730.],\n",
      "           [ 4532.,  4874.],\n",
      "           [ 4664.,  5018.],\n",
      "           [ 4796.,  5162.],\n",
      "           [ 4928.,  5306.]])\n",
      "    >>> np.einsum(a, [0,1,2], b, [1,0,3], [2,3])\n",
      "    array([[ 4400.,  4730.],\n",
      "           [ 4532.,  4874.],\n",
      "           [ 4664.,  5018.],\n",
      "           [ 4796.,  5162.],\n",
      "           [ 4928.,  5306.]])\n",
      "    >>> np.tensordot(a,b, axes=([1,0],[0,1]))\n",
      "    array([[ 4400.,  4730.],\n",
      "           [ 4532.,  4874.],\n",
      "           [ 4664.,  5018.],\n",
      "           [ 4796.,  5162.],\n",
      "           [ 4928.,  5306.]])\n",
      "    \n",
      "    Writeable returned arrays (since version 1.10.0):\n",
      "    \n",
      "    >>> a = np.zeros((3, 3))\n",
      "    >>> np.einsum('ii->i', a)[:] = 1\n",
      "    >>> a\n",
      "    array([[ 1.,  0.,  0.],\n",
      "           [ 0.,  1.,  0.],\n",
      "           [ 0.,  0.,  1.]])\n",
      "    \n",
      "    Example of ellipsis use:\n",
      "    \n",
      "    >>> a = np.arange(6).reshape((3,2))\n",
      "    >>> b = np.arange(12).reshape((4,3))\n",
      "    >>> np.einsum('ki,jk->ij', a, b)\n",
      "    array([[10, 28, 46, 64],\n",
      "           [13, 40, 67, 94]])\n",
      "    >>> np.einsum('ki,...k->i...', a, b)\n",
      "    array([[10, 28, 46, 64],\n",
      "           [13, 40, 67, 94]])\n",
      "    >>> np.einsum('k...,jk', a, b)\n",
      "    array([[10, 28, 46, 64],\n",
      "           [13, 40, 67, 94]])\n",
      "    \n",
      "    Chained array operations. For more complicated contractions, speed ups\n",
      "    might be achieved by repeatedly computing a 'greedy' path or pre-computing the\n",
      "    'optimal' path and repeatedly applying it, using an\n",
      "    `einsum_path` insertion (since version 1.12.0). Performance improvements can be\n",
      "    particularly significant with larger arrays:\n",
      "    \n",
      "    >>> a = np.ones(64).reshape(2,4,8)\n",
      "    # Basic `einsum`: ~1520ms  (benchmarked on 3.1GHz Intel i5.)\n",
      "    >>> for iteration in range(500):\n",
      "    ...     np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a)\n",
      "    # Sub-optimal `einsum` (due to repeated path calculation time): ~330ms\n",
      "    >>> for iteration in range(500):\n",
      "    ...     np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='optimal')\n",
      "    # Greedy `einsum` (faster optimal path approximation): ~160ms\n",
      "    >>> for iteration in range(500):\n",
      "    ...     np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='greedy')\n",
      "    # Optimal `einsum` (best usage pattern in some use cases): ~110ms\n",
      "    >>> path = np.einsum_path('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='optimal')[0]\n",
      "    >>> for iteration in range(500):\n",
      "    ...     np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize=path)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.einsum)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
